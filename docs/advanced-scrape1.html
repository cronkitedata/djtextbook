<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title> 25 Scraping without programming | Data Reporting, Spring 2022</title>
<meta name="author" content="Sarah Cohen">
<meta name="description" content="This book will introduce scraping websites in three sections. This section contains the vocabulary you need and strategies to avoid scraping altogether by finding data already on your computer and...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content=" 25 Scraping without programming | Data Reporting, Spring 2022">
<meta property="og:type" content="book">
<meta property="og:url" content="https://github.com/cronkitedata/djtextbook/advanced-scrape1.html">
<meta property="og:description" content="This book will introduce scraping websites in three sections. This section contains the vocabulary you need and strategies to avoid scraping altogether by finding data already on your computer and...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content=" 25 Scraping without programming | Data Reporting, Spring 2022">
<meta name="twitter:site" content="@sarahcnyt">
<meta name="twitter:description" content="This book will introduce scraping websites in three sections. This section contains the vocabulary you need and strategies to avoid scraping altogether by finding data already on your computer and...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.11/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><link href="libs/_Muli-0.4.0/font.css" rel="stylesheet">
<script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/core-js-2.5.3/shim.min.js"></script><script src="libs/react-17.0.0/react.min.js"></script><script src="libs/react-17.0.0/react-dom.min.js"></script><script src="libs/reactwidget-1.0.0/react-tools.js"></script><script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script><script src="libs/reactable-binding-0.2.3/reactable.js"></script><script src="libs/plotly-binding-4.10.0/plotly.js"></script><script src="libs/typedarray-0.1/typedarray.min.js"></script><link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet">
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script><link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet">
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script><link rel="shortcut icon" href="assets/images/favicon.ico">
<!--
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Work+Sans:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
        --><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Data Reporting, Spring 2022</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li class="book-part">Reporting with data</li>
<li><a class="" href="starter-intro.html">In this section</a></li>
<li><a class="" href="start-story.html"><span class="header-section-number">1</span> Learn a new way to read</a></li>
<li><a class="" href="start-math.html"><span class="header-section-number">2</span> Newsroom math</a></li>
<li><a class="" href="start-data-def.html"><span class="header-section-number">3</span> Defining “Data”</a></li>
<li><a class="" href="start-data-diary.html"><span class="header-section-number">4</span> Replication and the data diary</a></li>
<li><a class="" href="start-hunt.html"><span class="header-section-number">5</span> Finding the right data for your story</a></li>
<li><a class="" href="start-build-own.html"><span class="header-section-number">6</span> Build your own database</a></li>
<li class="book-part">Spreadsheets</li>
<li><a class="" href="xl-intro.html">Introduction</a></li>
<li><a class="" href="xl-refresher.html"><span class="header-section-number">7</span> An Excel Refresher</a></li>
<li><a class="" href="xl-filter-sort.html"><span class="header-section-number">8</span> Sorting and filtering to find stories</a></li>
<li><a class="" href="xl-pivot.html"><span class="header-section-number">9</span> Grouping with pivot tables</a></li>
<li><a class="" href="xl-formulas.html"><span class="header-section-number">10</span> Formulas in Excel</a></li>
<li><a class="" href="xl-practice-noc.html"><span class="header-section-number">11</span> Practice exercise</a></li>
<li class="book-part">R Study Guide</li>
<li><a class="" href="r-intro.html">Introduction</a></li>
<li><a class="" href="r-start.html"><span class="header-section-number">12</span> Getting started with R and RStudio</a></li>
<li><a class="" href="r-markdown.html"><span class="header-section-number">13</span> R Markdown</a></li>
<li><a class="" href="r-data-import.html"><span class="header-section-number">14</span> Getting and saving data</a></li>
<li><a class="" href="r-verbs.html"><span class="header-section-number">15</span> A quick tour of verbs</a></li>
<li><a class="" href="r-verb-filter.html"><span class="header-section-number">16</span> Verbs in depth: Select, filter, arrange</a></li>
<li><a class="" href="r-verb-groupby.html"><span class="header-section-number">17</span> Verbs in depth: Aggregating with groups</a></li>
<li><a class="" href="r-verb-mutate.html"><span class="header-section-number">18</span> Verbs in depth: New from old data with Mutate</a></li>
<li><a class="" href="r-verb-join.html"><span class="header-section-number">19</span> Verbs in depth: Matchmaking with joins</a></li>
<li><a class="" href="r-recipes.html"><span class="header-section-number">20</span> Recipes</a></li>
<li class="book-part">Visualization as a reporting tool</li>
<li><a class="" href="viz-intro.html">Introduction</a></li>
<li><a class="" href="viz-reporting.html"><span class="header-section-number">21</span> Visualization as a reporting tool</a></li>
<li><a class="" href="viz-demo.html"><span class="header-section-number">22</span> Visualization demo</a></li>
<li class="book-part">Special skills</li>
<li><a class="" href="advanced-intro.html">Introduction</a></li>
<li><a class="" href="advanced-regex.html"><span class="header-section-number">23</span> Regular Expressions for pattern matching</a></li>
<li><a class="" href="advanced-openrefine.html"><span class="header-section-number">24</span> Open refine walkthrough</a></li>
<li><a class="active" href="advanced-scrape1.html"><span class="header-section-number">25</span> Scraping without programming</a></li>
<li><a class="" href="advanced-scrape2.html"><span class="header-section-number">26</span> Introduction to scraping in R</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="appendix-math.html"><span class="header-section-number">A</span> Newsroom numbers cheat sheet</a></li>
<li><a class="" href="appendix-program.html"><span class="header-section-number">B</span> A gentle intro to programming</a></li>
<li><a class="" href="appendix-glossary.html"><span class="header-section-number">C</span> Glossary</a></li>
<li><a class="" href="appendix-resources.html"><span class="header-section-number">D</span> Great R Resources</a></li>
<li><a class="" href="appendix-ppp.html"><span class="header-section-number">E</span> Documentation for PPP data chapters</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="advanced-scrape1" class="section level1" number="25">
<h1>
<span class="header-section-number"> 25</span> Scraping without programming<a class="anchor" aria-label="anchor" href="#advanced-scrape1"><i class="fas fa-link"></i></a>
</h1>
<p>This book will introduce scraping websites in three sections.</p>
<p>This section contains the vocabulary you need and strategies to avoid scraping altogether by finding data already on your computer and using Google Sheets for simple lists.</p>
<p>The next chapter reviews how t o pick apart a page using the R library <code>rvest</code>, which is used to parse web pages.</p>
<p>The last chapter shows you how to programmatically walk through a lot of pages to recompile a more detailed or larger dataset. That chapter will also introduce you to the concept of <code>looping</code>, which we briefly mentioned inth <a href="docs/appendix-program.html">introduction to programming</a>.</p>
<div id="where-reporters-get-data" class="section level2" number="25.1">
<h2>
<span class="header-section-number">25.1</span> Where reporters get data<a class="anchor" aria-label="anchor" href="#where-reporters-get-data"><i class="fas fa-link"></i></a>
</h2>
<p>Reporters can get data from people, using FOIA, asking nicely or by finding a whistleblower to leak it. But we often also get data from publicly published sources, usually on the web.</p>
<p>There are three ways to get data from the web:</p>
<ul>
<li><p>Download it, or use an API<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;“application programming interface”&lt;/p&gt;"><sup>28</sup></a>. In these cases, the makers of the data have specifically offered it up for your use in a useful format. We’ll cover API’s later, but don’t forget to study the site for a download link or option. If there isn’t one on a government site, you might call the agency and ask that they add one. They might just do it. We’ve been using downloadable data throughout this book.</p></li>
<li><p>Find it on your browser. Often the person making the website delivers structured data to your browser as a convenience. It’s easier for them to make interactive items on their page by using data they’ve already delivered in visualizations and tables. It also reduces the loads on their servers. These are usually in JSON format. You might be able to find it right on your computer. It’s a miracle!</p></li>
<li><p>Scrape it. This set of chapters goes over how to scrape content that is delivered in HTML form – a web page. There would be other methods to scrape PDFs, which can be easy or hard.</p></li>
</ul>
</div>
<div id="a-json-miracle-walkthrough" class="section level2" number="25.2">
<h2>
<span class="header-section-number">25.2</span> A json miracle walkthrough<a class="anchor" aria-label="anchor" href="#a-json-miracle-walkthrough"><i class="fas fa-link"></i></a>
</h2>
<p>This walkthrough shows you how to find some json in your browser. Use the Chrome browser for this - Firefox and Safari also have similar features, but they look different.</p>
<p><a href="https://cronkitedata.s3.amazonaws.com/docs/simple-page.html">Here is a simple page</a> that will show you what the json looks like and how to extract it. This is what a human sees:</p>
<div class="inline-figure"><img src="assets/images/advanced-scrape1-human.png" style="width:100.0%"></div>
<p>The table of presidents is actually produced using a small javascript program inside the HTML that walks through each item and lists it as a row.</p>
<ul>
<li><p>Open the page in Chrome, then right-click anywhere on the page and choose “Inspect”. It may appear as just two items - the “head” and the “body”. But notice the little arrows - they show you that there is more content underneath. For now, we’ll ignore this, but it will be important later.</p></li>
<li><p>Choose the Network tab, then re-load the page.</p></li>
</ul>
<div class="figure">
<img src="assets/images/advanced-scrape1-inspect.png" style="width:100.0%" alt=""><p class="caption">inspect network</p>
</div>
<p>This shows you everything that the browser is attempting to load into your browser. (You may not see the “favicon” item. I have no idea why it’s showing up on mine - it’s not been requested!)</p>
<p>You can ignore most of this. Importantly, the “simple-page.html” is the actual page, and the “simple.json” is the data! Click on the simple.json row, then choose the “Response” tab:</p>
<div class="figure">
<img src="assets/images/advanced-scrape1-simplejson.png" style="width:80.0%" alt=""><p class="caption">simple json</p>
</div>
<p>That’s what json looks like - a list of rows within an item called “presidents”, each identified by the name of the column they’ll become.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;In R, our style was to name columns in lower case with words separated by underscores. In Javascript, the custom is usually called “camel case”, with words smushed together and the first letter of each upper cased. It’s just a custom, not a rule.&lt;/p&gt;"><sup>29</sup></a></p>
<ul>
<li><p>Right-click on the simple.json file name, and you’ll see a lot of options. Choose the one that says <em>Copy-&gt;Copy link address</em>.</p></li>
<li><p>Go to a new browser window and search for “json to csv”. <a href="https://www.convertcsv.com/json-to-csv.htm">This one</a> is one that I often see first.</p></li>
<li><p>Paste your copied link in the tab that says, “Enter URL” and press “Load URL”. You’ll see an option to copy the result as a csv file!</p></li>
</ul>
<div class="figure">
<img src="assets/images/advanced-scrape1-jsontocsv.png" style="width:100.0%" alt=""><p class="caption">json to csv</p>
</div>
<div id="a-harder-example" class="section level3" number="25.2.1">
<h3>
<span class="header-section-number">25.2.1</span> A harder example<a class="anchor" aria-label="anchor" href="#a-harder-example"><i class="fas fa-link"></i></a>
</h3>
<p>That was easy! But it’s also trivial. However, this method can often save you from having to page through results of a page. One example is the <a href="https://www.mcso.org/i-want-to/mugshot-lookup">Maricopa County nightly list of mugshots</a>, which may have several hundred new entries each day. Here’s what today’s looked like on a desktop browser (it looks different on a smaller screen).<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;I’m hiding names of people to the extent possible, and won’t list them in text here - they’ll only be in the images. Instead, I’ll show pictures of how to find the json when a name is necessary. Although this book is probably not indexed by Google, it’s possible that it could be some day, and I don’t want their names to show up in a Google search.&lt;/p&gt;"><sup>30</sup></a>:</p>
<div class="figure">
<img src="assets/images/advanced-scrape1-mcso1.png" style="width:100.0%" alt=""><p class="caption">mcso list</p>
</div>
<p>It looks like you’d have to go through each of the five pages to get all of the names of people who were booked into jail that night, but often a json file contains all of them – they’re just showing you one page at a time.</p>
<ul>
<li>This page won’t let you right-click to get the inspector. Instead, on a Mac, press <code>Opt-Cmd-C</code> to open the inspector window. (I think it’s Shft-Ctl-C on Windows, but I’m not sure.)</li>
</ul>
<p>This looks like a mess! Don’t worry. Switch to the Network tab, and re-load the page. This time, there are dozens of different things that get loaded on your page, and none of them are obviously json. You have a few strategies to find it.</p>
<ul>
<li>Press the “Fetch/XHR” tab to see if it shows up there. Use the “Preview” tab to look at what each of them is, and, miracle of miracles, it’s the third one on the list! Even better, it has all 425 entries! (It looks like they’re split into groups of 100, but they really aren’t.)</li>
</ul>
<div class="figure">
<img src="assets/images/advanced-scrape1-miracle1.png" style="width:100.0%" alt=""><p class="caption">miracle 1</p>
</div>
<ul>
<li>Right-click on the name of the file, and choose Copy-&gt;Copy link, and repeat the process above to convert it to a CSV file.</li>
</ul>
</div>
<div id="an-even-harder-example" class="section level3" number="25.2.2">
<h3>
<span class="header-section-number">25.2.2</span> An even harder example<a class="anchor" aria-label="anchor" href="#an-even-harder-example"><i class="fas fa-link"></i></a>
</h3>
<p>The New York Times <a href="https://www.nytimes.com/interactive/2020/us/covid-19-vaccine-doses.html">maintains a map</a> with the vaccination rates for various demographic groups by county on its website. At first, the Times didn’t provide a Github repo for the data. How can we extract the data from this map?</p>
<p>The easiest way would be to see if it contains a json miracle!</p>
<ul>
<li>Open your inspector panel</li>
<li>Copy and paste the link to the <a href="https://www.nytimes.com/interactive/2020/us/covid-19-vaccine-doses.html">map page</a>, and open it in your Chrome browser with the inpsectors showing.</li>
<li>Switch to the network tab. (If you opened the map before opening the inspector, reload it now. )</li>
</ul>
<p>Yikes! The “Fetch /XHR” button doesn’t help us much here. There are too many different json files to check. We could look one by one and see if they’re right, but sometimes that’s just too hard. Instead,</p>
<ul>
<li>Open the “Search” button on your inspector (it’s different from the Filter), and type in a county name (this one is “Maricopa”). You should see only a few of them. The most promising is the “doses_county.json”, so try that one first:</li>
</ul>
<div class="figure">
<img src="assets/images/advanced-scrape1-nytexample.png" style="width:100.0%" alt=""><p class="caption">nyt example</p>
</div>
<p>This time, it’s hard to find the item in the list of files in the browser. Instead, right-click in the “Preview” area, and copy the object. You can paste that into the box in the JSON to csv converter instead of entering a URL.</p>
</div>
</div>
<div id="no-json-no-problem-maybe" class="section level2" number="25.3">
<h2>
<span class="header-section-number">25.3</span> No json? No problem (maybe)<a class="anchor" aria-label="anchor" href="#no-json-no-problem-maybe"><i class="fas fa-link"></i></a>
</h2>
<p>You may not be able to find a json file – either it’s too hard to find, or it’s not useful, or it doesn’t exist. For a simple page, there’s no problem getting the data in Google Sheets. (This is one area where Excel lags behind Google Sheets.) We’ll go into HTML tags in more depth in the next chapter, but if your data is held in a table or structured list, you can import it directly into Google sheets.</p>
<p>Note that this trick is really only useful if your page doesn’t change a lot, or if you just want a one-time snapshot. It doesn’t automatically update, and I don’t know how to capture changes – it would involve a Google scripting program, which I don’t know how to do. I’ve never learned because I usually only gather data for my own use, and it’s easier to program it than to finagle Google Sheets.</p>
<p>The trick to using Google Sheets is to find a table tag (<code>&lt;table&gt;</code>) or a list tag (<code>&lt;ul&gt;</code> or <code>&lt;ol&gt;</code>) that contains the data you want.</p>
<p>Here’s an example, taken from a previous year’s MAIJ cohort: Reporters wanted to know whether Scottsdale was relatively unique in its city council structure, which has no districts. All members are at-large. Some research suggests that this disempowers non-white or less wealthy areas, because more privileged residents are often more active in local politics.</p>
<p>The reporters knew it was rare, but one question nagged at them: Was Scottsdale the largest city in the nation with a purely at-large council? That would make a nice tidbit for the story, but it wasn’t worth a major data collection endeavor.</p>
<p>Ballotpedia, a crowdsourced website with information on local governments, had collected a <a href="https://ballotpedia.org/List_of_current_city_council_officials_of_the_top_100_cities_in_the_United_States">page of city council officials in the 100 largest cities</a> in the US. Extracting this information into a structured table, then using regular expressions, could help make that a relatively simple job. This could even be done in Google Sheets, which also has a regular expression implementation. Because it’s so rare, just getting a list of cities that had no district or ward membership would give them a place to start looking up populations.</p>
This information is stored in an HTML table, identified by the “
<div class="inline-table"><table class="table table-sm">
<p>” element.</p>
<ul>
<li>Right-click on the page, and open your inspector. It looks like a mess, but you can search for tables using a simple “Find” using Cmd (or Ctl) -F.</li>
</ul>
<p>You may notice it says you can find by string, selector or XPath.</p>
<ul>
<li><p>In the box, enter “&lt;table” (with the opening “&lt;”, but no closing one.). You should see “1 of 12” in the result box. As you go through the list, the currently selected table will be highlighted. When you hit “3 of 12”, you’ll notice that the browser has selected the table you want. That’s the information we need.</p></li>
<li><p>Open a Google Sheet, and copy the page URL to cell A1. This just makes it easier to construct the formula to extract the table.</p></li>
<li><p>In cell A3, enter the following formula:</p></li>
</ul>
<div class="sourceCode" id="cb147"><pre class="sourceCode markdown"><code class="sourceCode markdown"><span id="cb147-1"><a href="advanced-scrape1.html#cb147-1" aria-hidden="true" tabindex="-1"></a><span class="in">      </span></span>
<span id="cb147-2"><a href="advanced-scrape1.html#cb147-2" aria-hidden="true" tabindex="-1"></a><span class="in">      =ImportHTML(A1, "table", 3)</span></span></code></pre></div>
<p>That means, “Go to the web address listed in cell A1, look for”table” tags, then return whatever is in the third one.”</p>
<div class="figure">
<img src="assets/images/advanced-scrape1-googlesheet1.png" style="width:100.0%" alt=""><p class="caption">googlesheet</p>
</div>
<p>When you hit “enter” the whole table will populate on your Google Sheet. Unfortunately, you can’t get the link to the city from this method, which means you don’t have a good way to extract a city name. We’ll come back to this when we go to scraping in R. (There is a way to get this in Google Sheets, but it’s not very reliable – it will choke as soon as it encounters a missing URL.)</p>
<p>But if you just need the text of a table or list in a spreadsheet, this is an easy way to get it. (To get a list from an “ol” or “ul” (ordered and unordered lists) tag, use “list” instead of “table”.)</p>

<div id="recap" class="section level2" number="25.4">
<h2>
<span class="header-section-number">25.4</span> Recap<a class="anchor" aria-label="anchor" href="#recap"><i class="fas fa-link"></i></a>
</h2>
<p>Sometimes – especially on modern websites that create interactive elements on the fly – the data you need is already sitting on your computer. In fact, it’s quite hard to scrape those in other ways because the HTML is created when it’s loaded into your browser.</p>
<p>But when it’s not, there may be another simple way to get the content.</p>
<p>The problem is that getting the content without programming can leave you unsatisfied because you can only get the text, not any of the underlying information. The next chapter shows you one method of getting more information from a web page using CSS selectors.</p>
<p>I sometimes use a Chrome extension called “Chrome Scraper” to get slightly more complex information out of a website, which uses a language called XPath to parse a web page. It’s harder than the CSS selector method, though, so I’m skipping it for now.</p>

</div>


  

  


 <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Data Reporting, Spring 2022</strong>" was written by Sarah Cohen. It was last built on 2022-03-31.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer>
</table></div>
</div>
</div>
<div class="chapter-nav">
<div class="prev"><a href="advanced-openrefine.html"><span class="header-section-number">24</span> Open refine walkthrough</a></div>
<div class="next"><a href="advanced-scrape2.html"><span class="header-section-number">26</span> Introduction to scraping in R</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#advanced-scrape1"><span class="header-section-number">25</span> Scraping without programming</a></li>
<li><a class="nav-link" href="#where-reporters-get-data"><span class="header-section-number">25.1</span> Where reporters get data</a></li>
<li>
<a class="nav-link" href="#a-json-miracle-walkthrough"><span class="header-section-number">25.2</span> A json miracle walkthrough</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#a-harder-example"><span class="header-section-number">25.2.1</span> A harder example</a></li>
<li><a class="nav-link" href="#an-even-harder-example"><span class="header-section-number">25.2.2</span> An even harder example</a></li>
</ul>
</li>
<li><a class="nav-link" href="#no-json-no-problem-maybe"><span class="header-section-number">25.3</span> No json? No problem (maybe)</a></li>
<li><a class="nav-link" href="#recap"><span class="header-section-number">25.4</span> Recap</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>
</div>
</div>
</body>
</html>
