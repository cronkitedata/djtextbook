{
  "hash": "ea28e4e37203103fde1d9acf46ab9724",
  "result": {
    "markdown": "# Regular Expressions for pattern matching {#advanced-regex} \n\n*Regular expressions* are used to find and replace text based on *patterns* rather than *characters*. They're particularly useful when trying to pull apart and standardize variables in a database such as names, phone numbers and addresses to make grouping and joining more effective.\n\nA human can easily discern that the name *John W. Smith, Jr.*  and *Smith, John W Jr* are probably the same. A computer sees them as completely different -- they don't start with the same characters, they have commas in different places, etc. A regular expression can help you pull apart names based on their pieces and then put them back together in another form.\n\nThere are two or or three parts to a regular expression:   \n\n1. The pattern you are trying to find.\n2. An optional replacement, which could use part of what you've found in the original seeking phase.\n3. Options - the big one in R is `negate=TRUE`, which means to match everything EXCEPT what is found.\n\nIn practice, you'll usually save the pieces of each pattern you've found into a variable, then put them back together differently.\n\nHere are two other good tutorials on regular expressions: \n\n* [From Justin Meyer](https://cronkitedata.s3.amazonaws.com/docs/meyer_regex.pdf) at a recent IRE conference that can serve as a guide.  \n* [From Prof. Christian McDonald of UT-Austin](https://cronkitedata.s3.amazonaws.com/docs/regex_for_rest_of_us.pdf)\n\n* If you're using R, you can use a regex using the `stringr` package (part of the tidyverse) using the functions *str_detect* , *str_extract* and their cousins. They look like this:  \n\n```markdown\n    str_detect(var_name, regex(\"pattern\")) \n````\n\n* The [vignette on the `stringr` package](https://stringr.tidyverse.org/) in the Tidyverse is reasonably helpful. \n\n## Types of regular expression patterns\n\n### Literal strings\n\nThese are just letters, like \"abc\" or \"Mary\". They are case-sensitive and no different than using text in a filter.\n\nYou can tell the regex that you want to find your pattern at the beginning or end of a line:\n\n```markdown\n  ^   = \"Find only at the beginning of a line\"\n  $   = \"Find only at the end of a line\"\n```\n\n### Wild cards\n\nA wild card is a character you use to indicate the word \"anything\". Here are some ways to use wild cards in regex:\n\n```markdown\n    .      = \"any single character of any type\"\n    .?     = \"a possible single character of any type (but it might not exist)\"\n    .*     = \"anything or nothing of any length\"\n    .+     = \"anything one or more times\"\n    .{1,3} = \"anything running between 1 and 3 characters long\"\n```\n\nRegular expressions also have wild cards of specific types. In R, they are \"escaped\" using two backslashes. In other languages and in the example <https://regex101.com> site they only use one backslash:\n\n```markdown\n      \\\\d   = \"Any digit\"\n      \\\\w   = \"Any word character\"\n      \\\\s   = \"Any whitespace (tab, space, etc.)\"\n      \\\\b   = \"Any word boundary\" (period, comma, space, etc.)\n```\n\nWhen you upper-case them, it's the opposite:\n\n```markdown\n      \\\\D = \"Anything but a digit\"\n```\n### Character classes\n\nSometimes you want to tell the regex what characters it is allowed to accept. For example, say you don't know whether there is an alternative spelling for a name -- you can tell the regex to either ignore a character, or take one of several.\n\nIn R, we saw that there were alternative spellings for words like \"summarize\" -- the British and the American spellings. You could, for example, use this pattern to pick up either spelling:\n\n```markdown\n        summari[sz]e\n```\n\nThe bracket tells the regex that it's allowed to take either one of those characters. You can also use ranges:\n\n      [a-zA-Z0-9]\n\nmeans that any lower case, upper case or numeric character is allowed.\n\n### Escaping\n\nBecause they're already being used for special purposes, some characters have to be \"escaped\" before you can search for them. Notably, they are parentheses (), periods, backslashes, dollar signs, question marks, dashes and carets.\n\nThis means that to find a period or question mark, you have to use the pattern\n\n        \\\\. or\n        \\\\?\n\nIn the Regex101, this is the biggest difference among the flavors of regex -- Python generally requires the least amount of escaping.\n\n### Match groups\n\nUse parentheses within a pattern to pick out pieces, which you can then use over again. The end of this chapter shows how to do this in R, which is a little complicated because we haven't done much with `lists`. \n\n\n## Sample data\n\nHere are three small text files that you can copy and paste from your browser into the [regex101.com](https://regex101.com/) site. It's a site that lets you test out regular expressions, while explaining to you what's happening with them.\n\n1. A [list of phone numbers](https://cronkitedata.s3.amazonaws.com/csv/regex_phones.txt) in different formats\n2. A [list of dates](https://cronkitedata.s3.amazonaws.com/csv/regex_dates.txt) that you need to convert into a different form.\n3. A [list of addresses](https://cronkitedata.s3.amazonaws.com/csv/regex_addresses.txt) that are in multiple lines, and you need to pull out the pieces. (Courtesy of IRE)\n4. A [small chunk of the H2B visa applications](https://cronkitedata.s3.amazonaws.com/csv/regex_h2bvisas.txt) from Arizona companies or worksites that has been kind of messed up for this demonstration, in tab-delimited format.\n\n## Testing and examining patterns with Regex101 \n\n[Regex 101](https://regex101.com) is a website that lets you copy part of your data into a box, then test different patterns to see how they get applied. Regular expressions are very difficult to write and to read, but Regex101 lets you do it a little piece at a time. Just remember that every time you use '\\' in regex101, you will need '\\\\` in R. \n\n### Looking for specific words or characters\n\nThe easiest regex is one that has just the characters  you're looking for when you know that they are the right case. They're called *literals* because you are literally looking for those letters or characters.\n\n![](assets/images/advanced-regex1.png){width=100%}\n\n## Practice #1: Extract date parts\n\nIn Regex 101, change the \"Flavor\" to \"Python\" -- otherwise, you have to escape more of the characters.^[Each language implements regular expressions slightly differently -- when you begin to learn more languages, this will be one of the first things you'll need to look up.]\n\nWe want to turn dates that look like this:\n\n      1/24/2018\n\ninto something that looks like this:\n\n     2008-1-24\n\nCopy and paste these numbers into the regex 101 window:\n\n    9/7/2017\n    9/11/1998\n    9/11/2017\n    9/19/2018\n    9/15/2017\n    10/13/2019\n    11/3/2017\n\nFirst, you can use any digit using the pattern \"\\d\". Try to do it in pieces. First, see if you can find one or two digits at the beginning of the line.\n\n      ^\\d{1,2}\n\nTry coming up with the rest of it on your own before you type in the answer:\n\n      ^\\d{1,2}.\\d{1,2}.\\d{4}\n\n(This works because regular expressions normally are \"greedy\". That is, if you tell it \"one or two digits\", it will always take two if they exist.)\n\nPut parentheses around any pieces that you want to use for later:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](assets/images/advanced-regex4.png){width=80%}\n:::\n:::\n\n\nNow each piece has its section, numbered 0 for the whole match, and then 1-3 for the pieces.\n\n![](assets/images/advanced-regex3.png){width=100%}\n\n## Practice #2: Extract pieces of phone numbers\n\nHere are some phone numbers in different formats:\n\n```markdown\n    623-374-1167\n    760.352.5212\n    831-676-3833\n    (831)-676-3833\n    623-374-1167 ext 203\n    831-775-0370\n    (602)-955-0222  x20\n    928-627-8080\n    831-784-1453\n```\n\nThis is a little more complicated than it looks, so try piecing together what this one says:\n\n```markdown\n      (\\d{3})[-.\\)]+(\\d{3})[-.]+(\\d{4})\n```\n\n(This won't work in the \"substitute\" area -- it would be easier to create a new variable with the results than to replace the originals.)\n\nAnything within parentheses will be \"captured\" in a block.\n\n## Practice #3: Extract address pieces\n\nHere are a few lines of the data from [Prof. McDonald's tutorial](https://cronkitedata.s3.amazonaws.com/docs/regex_for_rest_of_us.pdf), which you can copy and paste to go his exercise. (He uses the Javascript version of regular expressions, but for our purposes in this exercise, it doesn't matter which one you use. If you choose Python,  you'll have one extra step, of putting a slash (\\) before the quotes. The colors work a little better if you leave it on the default PHP method.)\n\n```markdown\n    \"10111 N LAMAR BLVD\n    AUSTIN, TX 78753\n    (30.370945933000485, -97.6925542359997)\"\n    \"3636 N FM 620 RD\n    AUSTIN, TX 78734\n    (30.377873241000486, -97.9523496219997)\"\n    \"9919 SERVICE AVE\n    AUSTIN, TX 78743\n    (30.205028616000448, -97.6625588019997)\"\n    \"10601 N LAMAR BLVD\n    AUSTIN, TX 78753\n    (30.37476574700048, -97.6903937089997)\"\n    \"801 E WILLIAM CANNON DR Unit 205\n    AUSTIN, TX 78745\n    (30.190914575000477, -97.77193838799968)\"\n    \"4408 LONG CHAMP DR\n    AUSTIN, TX 78746\n    (30.340981111000474, -97.7983147919997)\"\n    \"625 W BEN WHITE BLVD EB\n    AUSTIN, TX 78745\n    (30.206884239000487, -97.7956469989997)\"\n    \"3914 N LAMAR BLVD\n    AUSTIN, TX 78756\n    (30.307477098000447, -97.74169675199965)\"\n    \"15201 FALCON HEAD BLVD\n    BEE CAVE, TX 78738\n    (30.32068282700044, -97.96890311999965)\"\n    \"11905 FM 2244 RD Unit 100\n    BEE CAVE, TX 78738\n    (30.308363203000454, -97.92393357799966)\"\n    \"3801 JUNIPER TRCE\n    BEE CAVE, TX 78738\n    (30.308247975000484, -97.93511531999968)\"\n    \"12800 GALLERIA CIR Unit 101\n    BEE CAVE, TX 78738\n    (30.307996778000472, -97.94065088199966)\"\n    \"12400 W SH 71 Unit 510\n    BEE CAVE, TX 78733\n    (30.330682136000462, -97.86979886299969)\"\n    \"716 W 6TH ST\n    AUSTIN, TX 78701\n    (30.27019732500048, -97.75036306299967)\"\n    \"3003 BEE CAVES RD\n    ROLLINGWOOD, TX 78746\n    (30.271592738000436, -97.79583786499967)\"\n```\n\n## On your own\n\n[This is a small list of H2A visa applications](https://cronkitedata.s3.amazonaws.com/csv/regex_h2bvisas.txt), which are requests for agricultural and seasonal workers, from companies or worksites in Arizona. Try importing it into Excel, then copying some of the cells to practice your regular expression skills.\n\nYou might try:\n\n* Finding all of the LLC's in the list (limited liability companies) of names. (You should turn on the case-insensitive flag in Regex 101 or set that flag in your program if you do.)\n* See how far you can get in standardizing the addresses.\n* Split the city, state and zip code of the worksite.\n* Find all of the jobs related to field crops such as lettuce or celery.\n\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [
      "advanced-regex_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}